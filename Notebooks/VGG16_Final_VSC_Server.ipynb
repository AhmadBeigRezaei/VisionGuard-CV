{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12447403-22ec-4730-8fd3-c9cbcab55ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchinfo import summary  # Model summary\n",
    "from torchvision.models import VGG16_Weights\n",
    "from tqdm import tqdm  # Progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6955fd6c-4f62-4490-a024-687bd70d3d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070957bc-3ab5-4b56-b06f-e002af3b9e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths to the dataset\n",
    "dataset_path_train = '/data/leuven/361/vsc36144/maibi_cv/Vision+/train'\n",
    "dataset_path_val = '/data/leuven/361/vsc36144/maibi_cv/Vision+/val'\n",
    "dataset_path_test = '/data/leuven/361/vsc36144/maibi_cv/Vision+/test'\n",
    "\n",
    "# Set Parameters for Training\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "input_shape = (224, 224)\n",
    "\n",
    "# Define data transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(input_shape),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_shape),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(input_shape),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(dataset_path_train, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(dataset_path_val, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(dataset_path_test, transform=data_transforms['test'])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "base_model = models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "base_model.classifier = nn.Sequential(\n",
    "    nn.Linear(base_model.classifier[0].in_features, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, len(train_dataset.classes)),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "base_model.to(device)\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for param in base_model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(base_model.classifier.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc35a05-91fa-448c-b157-f155e81c7fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation loop with progress bar\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Progress bar for training\n",
    "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\") as pbar:\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                pbar.set_postfix({\"Loss\": running_loss / (pbar.n + 1), \"Accuracy\": correct / total})\n",
    "                pbar.update()\n",
    "\n",
    "        train_accuracy = correct / total\n",
    "        val_loss, val_accuracy = evaluate_model(model, val_loader, criterion)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {running_loss/len(train_loader)}, Train Accuracy: {train_accuracy}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return running_loss/len(loader), correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025a01e0-82a1-4e53-84ec-4a3eb8802859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trained_model = train_model(base_model, train_loader, val_loader, criterion, optimizer, epochs=epochs)\n",
    "\n",
    "# Display the model summary\n",
    "summary(trained_model, input_size=(batch_size, 3, input_shape[0], input_shape[1]))\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(trained_model.state_dict(), '/data/leuven/361/vsc36144/maibi_cv/Saved_Model/openface_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ae2f0-452e-4cf7-9f78-c7d78a3dd86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = evaluate_model(trained_model, test_loader, criterion)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Calculate F1 score on the test dataset\n",
    "def calculate_f1(model, loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    return f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "f1score = calculate_f1(trained_model, test_loader)\n",
    "print(f\"F1 Score: {f1score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f3c786-198c-444b-82f6-fbebfa36899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the Currupted test dataset\n",
    "dataset_path_test_currupt_1 = '/data/leuven/361/vsc36144/maibi_cv/Vision+/corrupted_test/test_s_1_corr=gaussian_blur'\n",
    "dataset_path_test_currupt_2 = '/data/leuven/361/vsc36144/maibi_cv/Vision+/corrupted_test/test_s_2_corr=gaussian_blur'\n",
    "dataset_path_test_currupt_3 = '/data/leuven/361/vsc36144/maibi_cv/Vision+/corrupted_test/test_s_3_corr=gaussian_blur'\n",
    "dataset_path_test_currupt_4 = '/data/leuven/361/vsc36144/maibi_cv/Vision+/corrupted_test/test_s_4_corr=gaussian_blur'\n",
    "dataset_path_test_currupt_5 = '/data/leuven/361/vsc36144/maibi_cv/Vision+/corrupted_test/test_s_5_corr=gaussian_blur'\n",
    "\n",
    "# Load datasets\n",
    "test_dataset_1 = datasets.ImageFolder(dataset_path_test_currupt_1, transform=data_transforms['test'])\n",
    "test_dataset_2 = datasets.ImageFolder(dataset_path_test_currupt_2, transform=data_transforms['test'])\n",
    "test_dataset_3 = datasets.ImageFolder(dataset_path_test_currupt_3, transform=data_transforms['test'])\n",
    "test_dataset_4 = datasets.ImageFolder(dataset_path_test_currupt_4, transform=data_transforms['test'])\n",
    "test_dataset_5 = datasets.ImageFolder(dataset_path_test_currupt_5, transform=data_transforms['test'])\n",
    "\n",
    "# Calculate F1 score on the test dataset\n",
    "def calculate_f1(model, loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    return f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Create data loaders for TestDataset 1\n",
    "test_loader = DataLoader(test_dataset_1, batch_size=batch_size, shuffle=False)\n",
    "test_loss, test_accuracy = evaluate_model(trained_model, test_loader, criterion)\n",
    "print(f\"Test_1 Loss: {test_loss}\")\n",
    "print(f\"Test_1 Accuracy: {test_accuracy}\")\n",
    "f1score = calculate_f1(trained_model, test_loader)\n",
    "print(f\"F1 Score_1: {f1score}\")\n",
    "\n",
    "# Create data loaders for TestDataset 2\n",
    "test_loader = DataLoader(test_dataset_2, batch_size=batch_size, shuffle=False)\n",
    "test_loss, test_accuracy = evaluate_model(trained_model, test_loader, criterion)\n",
    "print(f\"Test_2 Loss: {test_loss}\")\n",
    "print(f\"Test_2 Accuracy: {test_accuracy}\")\n",
    "f1score = calculate_f1(trained_model, test_loader)\n",
    "print(f\"F1 Score_2: {f1score}\")\n",
    "\n",
    "# Create data loaders for TestDataset 3\n",
    "test_loader = DataLoader(test_dataset_3, batch_size=batch_size, shuffle=False)\n",
    "test_loss, test_accuracy = evaluate_model(trained_model, test_loader, criterion)\n",
    "print(f\"Test_3 Loss: {test_loss}\")\n",
    "print(f\"Test_3 Accuracy: {test_accuracy}\")\n",
    "f1score = calculate_f1(trained_model, test_loader)\n",
    "print(f\"F1 Score_3: {f1score}\")\n",
    "\n",
    "# Create data loaders for TestDataset 4\n",
    "test_loader = DataLoader(test_dataset_4, batch_size=batch_size, shuffle=False)\n",
    "test_loss, test_accuracy = evaluate_model(trained_model, test_loader, criterion)\n",
    "print(f\"Test_4 Loss: {test_loss}\")\n",
    "print(f\"Test_4 Accuracy: {test_accuracy}\")\n",
    "f1score = calculate_f1(trained_model, test_loader)\n",
    "print(f\"F1 Score_4: {f1score}\")\n",
    "\n",
    "# Create data loaders for TestDataset 5\n",
    "test_loader = DataLoader(test_dataset_5, batch_size=batch_size, shuffle=False)\n",
    "test_loss, test_accuracy = evaluate_model(trained_model, test_loader, criterion)\n",
    "print(f\"Test_5 Loss: {test_loss}\")\n",
    "print(f\"Test_5 Accuracy: {test_accuracy}\")\n",
    "f1score = calculate_f1(trained_model, test_loader)\n",
    "print(f\"F1 Score_5: {f1score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9517bc2f-5dc2-4775-a02e-e4b6f609bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Haar cascade face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load the trained OpenFace model\n",
    "trained_model.load_state_dict(torch.load('/data/leuven/361/vsc36144/maibi_cv/Saved_Model/openface_model.pth'))\n",
    "trained_model.to(device)\n",
    "trained_model.eval()\n",
    "\n",
    "# Define a function to detect and recognize facial expressions\n",
    "def detect_expression(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = image[y:y+h, x:x+w]\n",
    "        face = cv2.resize(face, input_shape)\n",
    "        face = transforms.ToTensor()(face).unsqueeze(0)\n",
    "        face = face.to(device)\n",
    "\n",
    "        # Predict the emotion class\n",
    "        with torch.no_grad():\n",
    "            outputs = trained_model(face)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            emotion_class = train_dataset.classes[predicted.item()]\n",
    "\n",
    "        # Draw bounding box and label on the image\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(image, emotion_class, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a226bc3-6437-432b-865d-7ae807f69e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an input image\n",
    "input_image = cv2.imread('Ahmad.JPG')\n",
    "\n",
    "# Detect and recognize facial expressions\n",
    "output_image = detect_expression(input_image)\n",
    "\n",
    "# Display the output image\n",
    "cv2.imshow('Facial Expression Recognition', output_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
