{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kode-git/FER-Visual-Transformers/blob/main/Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mgwx5OxPCw9"
   },
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyKFuFD8PLDx"
   },
   "source": [
    "We will analysis AVFER dataset and its properties before the data management in the preprocessing phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPu20H1PPRyr"
   },
   "source": [
    "## Install Dependencies and Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpf8rL4hO6FO",
    "outputId": "943e01e2-bd48-45c8-9fd1-8d802bc9808c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install Pillow\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wuEyu_OmPYgs"
   },
   "outputs": [],
   "source": [
    "# classic libraries for collections.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# utility library.\n",
    "import random, time, copy\n",
    "\n",
    "# plot libraries.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# libraries for image processing .\n",
    "import os, cv2, glob, imageio, sys\n",
    "from PIL import Image\n",
    "\n",
    "# warning library for service warnings.\n",
    "import warnings\n",
    "\n",
    "# utility functions for specific uses\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "# Google Colab library.\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eisrjG3sPZcr",
    "outputId": "f70a63da-0fda-43a9-a52d-0bb2c1a6dae1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1XhsbzGPkdz"
   },
   "source": [
    "## Image Worker Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poJSgMY7Poys"
   },
   "source": [
    "ImageWorker provides some useful functions:\n",
    "- Format Converter: For resize and move an image from *source_path* to *dest_path* filtered for *format_img*\n",
    "- List Classes: Listing the classes and put them in an array to manipulate the subfolders for class functions divisions.\n",
    "- Counter Samples per Class: Given a *dataset_path*, return a dictionary with counters of images classified by subfolders for plot or data visualization pourposes. \n",
    "- Counter Samples: Given a *dataset_path*, return a counter of images in the tree.\n",
    "- Extension Converter: Convert an image format for every image in a specified path\n",
    "- Counter Files Extension: Given a *path*, return the counter of image in the directory with a specific *format*\n",
    "- Navigate Path: Counter every file in a subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "80W3c24BPvEW"
   },
   "outputs": [],
   "source": [
    "class ImageWorker():\n",
    "    \"\"\"\n",
    "    Image Worker class for Data Integration.\n",
    "    This class manages images data, size and format.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "         pass\n",
    "\n",
    "    def format_converter(self, path, format_img, source_path, dest_path, resize=(224,224)):\n",
    "        \"\"\"\n",
    "        Move an image from source_path to dest_path.\n",
    "        Images selected follow format_img.\n",
    "        There is a default resize of (224,244).\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        for file in glob.glob(path + \"/*.\" + format_img):\n",
    "            img = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
    "            resized = cv2.resize(img, resize, interpolation=cv2.INTER_CUBIC)\n",
    "            cv2.imwrite(dest_path + \"resized_on_\" + source_path + \"_\" + str(count) + \".\"+ format_img, resized)\n",
    "            count += 1\n",
    "\n",
    "    def list_classes(self, dataset_path):\n",
    "        \"\"\"\n",
    "        List the classes of a dataset.\n",
    "        \"\"\"\n",
    "        langs = []\n",
    "        for el in glob.glob(dataset_path):\n",
    "          langs.append(os.path.basename(str(el)))\n",
    "        return langs\n",
    "\n",
    "\n",
    "    def counter_samples_on_class(self, dataset_path):\n",
    "      \"\"\"\n",
    "      Counts samples of classes.\n",
    "      Each class has its own counter.\n",
    "      Return a dictionary with (class, counter) pair.\n",
    "      \"\"\"\n",
    "      classes = self.list_classes(dataset_path)\n",
    "      counter_classes = {}\n",
    "      if dataset_path[len(dataset_path) - 1] == \"/\":\n",
    "          path = dataset_path\n",
    "      if dataset_path[len(dataset_path) - 1] == \"*\":\n",
    "          path = dataset_path[0:len(dataset_path) - 2] + \"/\"\n",
    "      else:\n",
    "          path = dataset_path + \"/\"\n",
    "      for class_ in classes:\n",
    "        counter = 0\n",
    "        for file in glob.glob(path + class_ + \"/*\"):\n",
    "            counter += 1\n",
    "        counter_classes[class_] = counter\n",
    "      return counter_classes\n",
    "\n",
    "\n",
    "    def counter_samples(self, dataset_path):\n",
    "      \"\"\"\n",
    "      Counts total samples of a dataset.\n",
    "      \"\"\"\n",
    "      a = self.counter_samples_on_class(dataset_path)\n",
    "      counter = 0\n",
    "      for el in a.keys():\n",
    "        counter += a[el]\n",
    "      return counter\n",
    "\n",
    "\n",
    "    def extension_converter(self, path, format_source, format_result, dest_path):   \n",
    "      \"\"\"\n",
    "      Convert a file from format_source to format_result.\n",
    "      The file is loaded from path and the result is stored to dest_path.\n",
    "      \"\"\"\n",
    "      for file in glob.glob(path + \"/*.\" + format_source):\n",
    "          im1 = Image.open(file)\n",
    "          im1.save(file[0:len(file)-4] + \".\" + format_result)\n",
    "          os.remove(file)\n",
    "\n",
    "\n",
    "    def counter_file_extension(self, path, format):\n",
    "      \"\"\"\n",
    "      Counts samples in path based on format input.\n",
    "      \"\"\"\n",
    "      counter = 0\n",
    "      for file in glob.glob(path + \"/*.\" + format):\n",
    "          counter += 1\n",
    "      return counter\n",
    "      \n",
    "\n",
    "    def navigate_path(self, path):    \n",
    "      \"\"\"\n",
    "      Navigate in the path and counts every file\n",
    "      \"\"\"\n",
    "      count = 0\n",
    "      for dir in os.listdir(path):\n",
    "          if os.path.isfile(os.path.join(path, dir)):\n",
    "              count += 1\n",
    "      return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "188cT6wqQaoL"
   },
   "outputs": [],
   "source": [
    "# define Image Worker instance\n",
    "iw = ImageWorker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yG9NqPwP0BJ"
   },
   "source": [
    "## Common utilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJOh1D_WP4Im"
   },
   "source": [
    "We implemented some logic and reusable functions useful for the data analysis or data manipulation phases. These functions carry out support routines for ImageWorker's class. They are:\n",
    "- Min, Max and Mean: According to values or set of values passed as parameter.\n",
    "- Plot Dataset: Function for plot image's dataset and color values according to the mean of classes cardinalities.\n",
    "- Channel Distribution: Analyze images and return counters of images for different channels dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gDISNgyBPxsN"
   },
   "outputs": [],
   "source": [
    "def mean(values):\n",
    "  \"\"\"\n",
    "  Calculates the mean in values.\n",
    "  \"\"\"\n",
    "  if len(values) <= 0:\n",
    "    return 0\n",
    "  else:\n",
    "    sum = 0\n",
    "    for el in values:\n",
    "      sum += el\n",
    "    return int(sum / len(values))\n",
    "\n",
    "def min(val):\n",
    "  \"\"\"\n",
    "  Calculates the minimum in val.\n",
    "  \"\"\"\n",
    "  min = sys.maxsize\n",
    "  for el in val.keys():\n",
    "    if val[el] < min:\n",
    "      min = val[el]\n",
    "  return min\n",
    "\n",
    "\n",
    "def max(val):\n",
    "  \"\"\"\n",
    "  Calculates the maximum in val.\n",
    "  \"\"\"\n",
    "  max = sys.minsize\n",
    "  for el in val.keys():\n",
    "    if val[el] > max:\n",
    "      max = val[el]\n",
    "  return max\n",
    "\n",
    "\n",
    "def plot_dataset(dataset_path, title=\"\"):\n",
    "  \"\"\"\n",
    "  Plot the dataset and color bars.\n",
    "  Color depends on the lower bound and upper bound.\n",
    "  The mean value is the congiuntion between lower and upper bound.\n",
    "  \"\"\"\n",
    "  classes = iw.list_classes(dataset_path)\n",
    "  l_classes = iw.counter_samples_on_class(dataset_path)\n",
    "\n",
    "  fig = plt.figure()\n",
    "  ax = fig.add_axes([0,0,1,1,])\n",
    "  x = [l_classes[class_] for class_ in classes]\n",
    "  y = [class_ for class_ in classes]\n",
    "  \n",
    "  colors = []\n",
    "  x_cap = mean(x)\n",
    "\n",
    "  # colors identify when the elements are greater or lesser than the mean values.\n",
    "  for el in x:\n",
    "    if el < x_cap:\n",
    "      colors.append(\"#BC3434\")\n",
    "    else:\n",
    "      colors.append(\"#49A131\")\n",
    "  ax.bar(y, x, color=colors)\n",
    "  plt.title(title)\n",
    "  plt.show()\n",
    "\n",
    "def plot_format(typed, format):\n",
    "  \"\"\"\n",
    "  Plot samples considering only a specific format.\n",
    "  \"\"\"\n",
    "  fig = plt.figure(figsize=(5.5,5.5))\n",
    "  ax = fig.add_axes([0,0,1,1])\n",
    "  cp = df[df['set'] == typed]\n",
    "  ax.bar(cp['class'], \n",
    "       cp[format])\n",
    "  plt.title(f'Amount of {format} images in the {typed} dataset')\n",
    "  plt.ylabel('Number')\n",
    "  plt.xlabel('Class')\n",
    "  plt.show()  \n",
    "\n",
    "def channels_distribution(dataset_path):\n",
    "  \"\"\"\n",
    "  Lists the channels dimensions of an image and return list of counters.\n",
    "  The indeces of the list are the numbers of channels.\n",
    "  The values are the number of files with a specific \n",
    "  number of channels corresponding to the index.\n",
    "  \"\"\"\n",
    "  chan_size = [0 for i in range(0, 5)]\n",
    "  for path in glob.glob(dataset_path):\n",
    "    for el in os.listdir(path):\n",
    "       pic = imageio.imread(path + \"/\" + el)\n",
    "       chan_size[pic.ndim] += 1\n",
    "  return chan_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8bJhK7rQF2I"
   },
   "source": [
    "## Analysis on AVFER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0q3Ve1eGPsXN"
   },
   "source": [
    "First of all, we need to check the amount of png and jpg on the training set. Actually, validation and testing set are in jpg image format due to the AffectNet splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JArufJwzRZ6C"
   },
   "outputs": [],
   "source": [
    "# dataset directory, classes folders and metadata dataframe declaration.\n",
    "basedir = \"/content/drive/MyDrive/Datasets/AVFER/*\"\n",
    "subsets = [dir for dir in glob.glob(basedir)]\n",
    "df = pd.DataFrame(data={\"class\" : [], \"jpg\" : [], \"png\" : [], \"set\" : []})\n",
    "\n",
    "# put in the dataframe metadata of images of AVFER.\n",
    "for dir in subsets:\n",
    "  classes = [cl for cl in glob.glob(dir + \"/*\")]\n",
    "  for cl in classes:\n",
    "    st = os.path.basename(dir)\n",
    "    cls = os.path.basename(cl)\n",
    "    png = iw.counter_file_extension(cl, \"png\")\n",
    "    jpg = iw.counter_file_extension(cl, \"jpg\")\n",
    "    df2 = pd.DataFrame(data={\n",
    "          \"class\" : [cls], \n",
    "          \"jpg\" : [jpg], \n",
    "          \"png\" : [png], \n",
    "          \"set\" : [st]\n",
    "    }) \n",
    "    df = pd.concat([df, df2], ignore_index = True, axis = 0)\n",
    "\n",
    "# display the head of the dataframe.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xea_5FihQhkS"
   },
   "outputs": [],
   "source": [
    "# plot samples in .jpg from the training set.\n",
    "plot_format('train', 'jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LaT0udY_Q011"
   },
   "outputs": [],
   "source": [
    "# plot samples in .png from the training set.\n",
    "plot_format('train', 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_391I4PAQ20M"
   },
   "outputs": [],
   "source": [
    "# AffectNet didn't have png, so we need to plot only .jpg on validation set.\n",
    "plot_format('val', 'jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vsTnOdR_RFsn"
   },
   "outputs": [],
   "source": [
    "# AffectNet didn't have png, so we need to plot only .jpg on testing set.\n",
    "plot_format('test', 'jpg')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMkoZKL7yavdRhiL8I97LiD",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Data_Analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
